{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programmers\\envs\\vit\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 2.4.1+cu118\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"D:/pytorch\")\n",
    "from segmentation_models_pytorch.utils.imports import *\n",
    "\n",
    "print_versions()\n",
    "\n",
    "# Select device (GPU or CPU)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 534, gt: 534\n",
      "Number of validation images: 150, gt: 150\n",
      "Number of test images: 138, gt: 138\n",
      "--------------------------------------------------\n",
      "Class Weights: {np.float32(0.0): np.float64(1.0), np.float32(1.0): np.float64(3.9)}\n"
     ]
    }
   ],
   "source": [
    "# Define the base directory for your dataset\n",
    "DATASET_DIR = \"VH\"\n",
    "img_sub, msk_sub = 'img', 'gt'\n",
    "\n",
    "# Load paths for training, validation, and test sets with default subdirectories\n",
    "train_imgs, train_masks = get_dataset_paths(DATASET_DIR, split='train', img_subdir=img_sub, mask_subdir=msk_sub, mask_ext='tiff')\n",
    "val_imgs, val_masks = get_dataset_paths(DATASET_DIR, split='val', img_subdir=img_sub, mask_subdir=msk_sub, mask_ext='tiff')\n",
    "test_imgs, test_masks = get_dataset_paths(DATASET_DIR, split='test', img_subdir=img_sub, mask_subdir=msk_sub, mask_ext='tiff')\n",
    "\n",
    "# Verify images\n",
    "print(f\"Number of training images: {len(train_imgs)}, gt: {len(train_masks)}\")\n",
    "print(f\"Number of validation images: {len(val_imgs)}, gt: {len(val_masks)}\")\n",
    "print(f\"Number of test images: {len(test_imgs)}, gt: {len(test_masks)}\")\n",
    "print(50*'-')\n",
    "\n",
    "weights = calculate_class_weights(train_masks)\n",
    "print(\"Class Weights:\", weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip()\n",
    "])\n",
    "\n",
    "# Train dataset with the same transformations for both images and masks\n",
    "train_dataset = Dataset2D(train_imgs, train_masks, transform=transform, transform_label=transform)\n",
    "\n",
    "# Validation and test datasets only convert to tensors\n",
    "val_dataset = Dataset2D(val_imgs, val_masks, transform=transforms.ToTensor(), transform_label=None)\n",
    "test_dataset = Dataset2D(test_imgs, test_masks, transform=transforms.ToTensor(), transform_label=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class UNetEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNetEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias=True):\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=self.input_dim + self.hidden_dim,\n",
    "            out_channels=4 * self.hidden_dim,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size // 2,\n",
    "            bias=bias\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        h_prev, c_prev = hidden\n",
    "\n",
    "        combined = torch.cat([x, h_prev], dim=1)  # Concatenate along channel axis\n",
    "        conv_output = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(conv_output, self.hidden_dim, dim=1)\n",
    "\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c = f * c_prev + i * g\n",
    "        h = o * torch.tanh(c)\n",
    "\n",
    "        return h, c\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            ConvLSTMCell(\n",
    "                input_dim=input_dim if i == 0 else hidden_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                kernel_size=kernel_size\n",
    "            ) for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, C, H, W]\n",
    "        B, T, C, H, W = x.shape\n",
    "        h, c = self.init_hidden(B, C, H, W)\n",
    "\n",
    "        outputs = []\n",
    "        for t in range(T):\n",
    "            inp = x[:, t, :, :, :]\n",
    "            for i, layer in enumerate(self.layers):\n",
    "                h[i], c[i] = layer(inp, (h[i], c[i]))\n",
    "                inp = h[i]\n",
    "            outputs.append(h[-1])\n",
    "\n",
    "        return torch.stack(outputs, dim=1), (h, c)\n",
    "\n",
    "    def init_hidden(self, B, C, H, W):\n",
    "        h = [torch.zeros(B, C, H, W, device=next(self.parameters()).device) for _ in range(self.num_layers)]\n",
    "        c = [torch.zeros(B, C, H, W, device=next(self.parameters()).device) for _ in range(self.num_layers)]\n",
    "        return h, c\n",
    "\n",
    "class CNNConvLSTMNet(nn.Module):\n",
    "    def __init__(self, cnn_backbone, feature_channels, temporal_channels, kernel_size, num_layers):\n",
    "        super(CNNConvLSTMNet, self).__init__()\n",
    "\n",
    "        # CNN Backbone (e.g., U-Net encoder or other feature extractor)\n",
    "        self.cnn_backbone = cnn_backbone\n",
    "\n",
    "        # ConvLSTM for temporal processing\n",
    "        self.conv_lstm = ConvLSTM(\n",
    "            input_dim=feature_channels,\n",
    "            hidden_dim=temporal_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        # Decoder for segmentation (basic example; replaceable by U-Net decoder)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(temporal_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Input tensor of shape [B, T, H, W]\n",
    "        \"\"\"\n",
    "        B, T, H, W = x.shape\n",
    "\n",
    "        # Step 1: Extract CNN features for each time frame\n",
    "        cnn_features = []\n",
    "        for t in range(T):\n",
    "            frame = x[:, t, :, :].unsqueeze(1)  # Extract frame [B, 1, H, W]\n",
    "            cnn_features.append(self.cnn_backbone(frame))  # Shape [B, C, H', W']\n",
    "        \n",
    "        cnn_features = torch.stack(cnn_features, dim=1)  # Shape [B, T, C, H', W']\n",
    "\n",
    "        # Step 2: Process features with ConvLSTM\n",
    "        conv_lstm_out, _ = self.conv_lstm(cnn_features)  # Shape [B, T, temporal_channels, H', W']\n",
    "\n",
    "        # Step 3: Decode the last ConvLSTM output\n",
    "        last_output = conv_lstm_out[:, -1, :, :, :]  # Use the last time step [B, temporal_channels, H', W']\n",
    "        segmentation_output = self.decoder(last_output)  # [B, 1, H, W]\n",
    "        \n",
    "        return segmentation_output.squeeze(1)  # [B, H, W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "\n",
    "\n",
    "class EfficientNetB0Backbone(nn.Module):\n",
    "    def __init__(self, pretrained=True, output_channels=32):\n",
    "        super(EfficientNetB0Backbone, self).__init__()\n",
    "        # Load EfficientNet-B0 model\n",
    "        if pretrained:\n",
    "            self.model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "        else:\n",
    "            self.model = efficientnet_b0(weights=None)\n",
    "        \n",
    "        # Modify the first convolutional layer to accept single-channel input\n",
    "        original_conv = self.model.features[0][0]\n",
    "        self.model.features[0][0] = nn.Conv2d(\n",
    "            in_channels=1,  # Single-channel input\n",
    "            out_channels=original_conv.out_channels,\n",
    "            kernel_size=original_conv.kernel_size,\n",
    "            stride=original_conv.stride,\n",
    "            padding=original_conv.padding,\n",
    "            bias=original_conv.bias\n",
    "        )\n",
    "\n",
    "        # Extract EfficientNet features (exclude classification head)\n",
    "        self.features = self.model.features\n",
    "\n",
    "        # Dynamically determine the number of output channels from the last feature layer\n",
    "        last_feature_channels = self.features[-1][0].out_channels\n",
    "\n",
    "        # Add a final convolutional layer to reduce channels to `output_channels`\n",
    "        self.reduce_channels = nn.Conv2d(\n",
    "            in_channels=last_feature_channels,\n",
    "            out_channels=output_channels,\n",
    "            kernel_size=1,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        # Remove hardcoded upsampling scale\n",
    "        self.upsample = nn.Upsample(mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the EfficientNetB0 backbone.\n",
    "        Args:\n",
    "            x: Input tensor of shape [B, 1, H, W] (single channel input).\n",
    "        Returns:\n",
    "            Features of shape [B, output_channels, H, W].\n",
    "        \"\"\"\n",
    "        input_size = x.shape[2:]  # Get input height and width (H, W)\n",
    "\n",
    "        # Extract features using EfficientNet\n",
    "        features = self.features(x)  # Shape [B, last_feature_channels, H', W']\n",
    "\n",
    "        # Reduce channels to the desired output\n",
    "        reduced_features = self.reduce_channels(features)  # Shape [B, output_channels, H', W']\n",
    "\n",
    "        # Adjust upsampling dynamically to match input size\n",
    "        self.upsample.scale_factor = (\n",
    "            input_size[0] / reduced_features.shape[2],\n",
    "            input_size[1] / reduced_features.shape[3],\n",
    "        )\n",
    "        upsampled_features = self.upsample(reduced_features)  # Shape [B, output_channels, H, W]\n",
    "\n",
    "        return upsampled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# Replace DummyCNN with UNetEncoder\n",
    "# cnn_backbone = UNetEncoder()\n",
    "cnn_backbone = EfficientNetB0Backbone(pretrained=True, output_channels=32)\n",
    "\n",
    "\n",
    "# Initialize the CNN-ConvLSTM model\n",
    "model = CNNConvLSTMNet(cnn_backbone, feature_channels=32, temporal_channels=32, kernel_size=3, num_layers=1)\n",
    "\n",
    "# Example input: [B, T, H, W]\n",
    "input_tensor = torch.randn(1, 11, 512, 512)\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)  # Expected: [B, H, W]\n",
    "\n",
    "if  output.shape[1:] != (512, 512):\n",
    "    raise ValueError(\"The output shape is incorrect!\")\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([2, 11, 512, 512])\n",
      "Label batch shape: torch.Size([2, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE_TRAIN = 2\n",
    "BATCH_SIZE_VALID = 2\n",
    "BATCH_SIZE_TEST = 2\n",
    "\n",
    "# Define the loss function (DiceLoss or CrossEntropyLoss)\n",
    "loss = smp.utils.losses.DiceLoss()  # Change to CrossEntropyLoss() if needed\n",
    "#loss = smp.utils.losses.CrossEntropyLoss()\n",
    "\n",
    "# Define the metric for evaluation. IoU (Intersection over Union) is a standard metric for segmentation.\n",
    "#metrics = [smp.utils.metrics.mIoU()]S\n",
    "metrics = [smp.utils.metrics.IoU()]\n",
    "\n",
    "# Initialize the optimizer\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE_VALID, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=False, num_workers=0)\n",
    "\n",
    "# Training loop setup using SMP utilities\n",
    "train_epoch = TrainEpoch(model, loss=loss, metrics=metrics, optimizer=opt, device=DEVICE)\n",
    "valid_epoch = ValidEpoch(model, loss=loss, metrics=metrics, device=DEVICE)\n",
    "\n",
    "# Verify batch\n",
    "for images, labels in train_loader:\n",
    "    print(\"Image batch shape:\", images.shape)\n",
    "    print(\"Label batch shape:\", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1/100\n",
      "train: 100%|██████████| 267/267 [8:12:49<00:00, 110.75s/it, DiceLoss - 0.3819, iou_score - 0.4769]  \n",
      "valid: 100%|██████████| 75/75 [10:56<00:00,  8.75s/it, DiceLoss - 0.2654, iou_score - 0.5872]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 2/100\n",
      "train: 100%|██████████| 267/267 [8:08:19<00:00, 109.74s/it, DiceLoss - 0.3057, iou_score - 0.5566]  \n",
      "valid: 100%|██████████| 75/75 [11:01<00:00,  8.82s/it, DiceLoss - 0.2247, iou_score - 0.6458]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 3/100\n",
      "train: 100%|██████████| 267/267 [7:50:02<00:00, 105.63s/it, DiceLoss - 0.2757, iou_score - 0.5921]  \n",
      "valid: 100%|██████████| 75/75 [10:23<00:00,  8.32s/it, DiceLoss - 0.3006, iou_score - 0.5608]\n",
      "\n",
      "Epoch: 4/100\n",
      "train: 100%|██████████| 267/267 [7:42:06<00:00, 103.84s/it, DiceLoss - 0.2336, iou_score - 0.6433]  \n",
      "valid: 100%|██████████| 75/75 [10:19<00:00,  8.26s/it, DiceLoss - 0.1911, iou_score - 0.6835]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 5/100\n",
      "train: 100%|██████████| 267/267 [7:43:07<00:00, 104.07s/it, DiceLoss - 0.1997, iou_score - 0.6874]  \n",
      "valid: 100%|██████████| 75/75 [10:20<00:00,  8.27s/it, DiceLoss - 0.1969, iou_score - 0.6825]\n",
      "\n",
      "Epoch: 6/100\n",
      "train: 100%|██████████| 267/267 [7:43:14<00:00, 104.10s/it, DiceLoss - 0.2013, iou_score - 0.6837]  \n",
      "valid: 100%|██████████| 75/75 [10:23<00:00,  8.32s/it, DiceLoss - 0.2336, iou_score - 0.6372]\n",
      "\n",
      "Epoch: 7/100\n",
      "train: 100%|██████████| 267/267 [7:54:41<00:00, 106.67s/it, DiceLoss - 0.2183, iou_score - 0.6658]  \n",
      "valid: 100%|██████████| 75/75 [11:05<00:00,  8.87s/it, DiceLoss - 0.2818, iou_score - 0.5686]\n",
      "\n",
      "Epoch: 8/100\n",
      "train: 100%|██████████| 267/267 [8:02:13<00:00, 108.37s/it, DiceLoss - 0.2064, iou_score - 0.6801]  \n",
      "valid: 100%|██████████| 75/75 [09:47<00:00,  7.84s/it, DiceLoss - 0.2505, iou_score - 0.6195]\n",
      "\n",
      "Epoch: 9/100\n",
      "train: 100%|██████████| 267/267 [7:40:24<00:00, 103.46s/it, DiceLoss - 0.1823, iou_score - 0.7127]  \n",
      "valid: 100%|██████████| 75/75 [09:49<00:00,  7.86s/it, DiceLoss - 0.2043, iou_score - 0.6749]\n",
      "\n",
      "Epoch: 10/100\n",
      "train: 100%|██████████| 267/267 [7:40:41<00:00, 103.53s/it, DiceLoss - 0.1885, iou_score - 0.7021]  \n",
      "valid: 100%|██████████| 75/75 [09:48<00:00,  7.84s/it, DiceLoss - 0.1651, iou_score - 0.7245]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 11/100\n",
      "train: 100%|██████████| 267/267 [7:40:45<00:00, 103.54s/it, DiceLoss - 0.1822, iou_score - 0.7141]  \n",
      "valid: 100%|██████████| 75/75 [09:47<00:00,  7.84s/it, DiceLoss - 0.1493, iou_score - 0.7457]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 12/100\n",
      "train: 100%|██████████| 267/267 [7:40:20<00:00, 103.45s/it, DiceLoss - 0.1814, iou_score - 0.7125]  \n",
      "valid: 100%|██████████| 75/75 [09:49<00:00,  7.86s/it, DiceLoss - 0.1565, iou_score - 0.7372]\n",
      "\n",
      "Epoch: 13/100\n",
      "train: 100%|██████████| 267/267 [7:40:28<00:00, 103.48s/it, DiceLoss - 0.1553, iou_score - 0.7434]  \n",
      "valid: 100%|██████████| 75/75 [09:49<00:00,  7.86s/it, DiceLoss - 0.2308, iou_score - 0.6405]\n",
      "\n",
      "Epoch: 14/100\n",
      "train: 100%|██████████| 267/267 [7:40:30<00:00, 103.49s/it, DiceLoss - 0.1856, iou_score - 0.7067]  \n",
      "valid: 100%|██████████| 75/75 [09:49<00:00,  7.86s/it, DiceLoss - 0.1695, iou_score - 0.7186]\n",
      "\n",
      "Epoch: 15/100\n",
      "train: 100%|██████████| 267/267 [7:40:50<00:00, 103.56s/it, DiceLoss - 0.1795, iou_score - 0.7156]  \n",
      "valid: 100%|██████████| 75/75 [09:49<00:00,  7.86s/it, DiceLoss - 0.1667, iou_score - 0.72]  \n",
      "\n",
      "Epoch: 16/100\n",
      "train: 100%|██████████| 267/267 [7:40:55<00:00, 103.58s/it, DiceLoss - 0.1713, iou_score - 0.7282]  \n",
      "valid: 100%|██████████| 75/75 [09:48<00:00,  7.85s/it, DiceLoss - 0.1496, iou_score - 0.7446]\n",
      "\n",
      "Epoch: 17/100\n",
      "train: 100%|██████████| 267/267 [7:40:47<00:00, 103.55s/it, DiceLoss - 0.1778, iou_score - 0.718]   \n",
      "valid: 100%|██████████| 75/75 [09:48<00:00,  7.85s/it, DiceLoss - 0.1615, iou_score - 0.7286]\n",
      "\n",
      "Epoch: 18/100\n",
      "train: 100%|██████████| 267/267 [7:40:41<00:00, 103.53s/it, DiceLoss - 0.1844, iou_score - 0.7103]  \n",
      "valid: 100%|██████████| 75/75 [09:48<00:00,  7.85s/it, DiceLoss - 0.1604, iou_score - 0.7312]\n",
      "\n",
      "Epoch: 19/100\n",
      "train: 100%|██████████| 267/267 [7:40:54<00:00, 103.57s/it, DiceLoss - 0.1511, iou_score - 0.7501]  \n",
      "valid: 100%|██████████| 75/75 [09:47<00:00,  7.84s/it, DiceLoss - 0.2514, iou_score - 0.6118]\n",
      "\n",
      "Epoch: 20/100\n",
      "train: 100%|██████████| 267/267 [7:40:15<00:00, 103.43s/it, DiceLoss - 0.1642, iou_score - 0.7343]  \n",
      "valid: 100%|██████████| 75/75 [09:48<00:00,  7.84s/it, DiceLoss - 0.1534, iou_score - 0.7409]\n",
      "\n",
      "Epoch: 21/100\n",
      "train: 100%|██████████| 267/267 [7:52:00<00:00, 106.07s/it, DiceLoss - 0.1637, iou_score - 0.7395]  \n",
      "valid: 100%|██████████| 75/75 [09:47<00:00,  7.84s/it, DiceLoss - 0.1551, iou_score - 0.7385]\n",
      "\n",
      "Epoch: 22/100\n",
      "train: 100%|██████████| 267/267 [7:40:38<00:00, 103.52s/it, DiceLoss - 0.1651, iou_score - 0.7386]  \n",
      "valid: 100%|██████████| 75/75 [09:52<00:00,  7.90s/it, DiceLoss - 0.1572, iou_score - 0.7349]\n",
      "\n",
      "Epoch: 23/100\n",
      "train: 100%|██████████| 267/267 [7:40:45<00:00, 103.54s/it, DiceLoss - 0.1501, iou_score - 0.7597]  \n",
      "valid: 100%|██████████| 75/75 [09:46<00:00,  7.82s/it, DiceLoss - 0.1853, iou_score - 0.699] \n",
      "\n",
      "Epoch: 24/100\n",
      "train: 100%|██████████| 267/267 [7:40:42<00:00, 103.53s/it, DiceLoss - 0.1382, iou_score - 0.7694]  \n",
      "valid: 100%|██████████| 75/75 [09:49<00:00,  7.86s/it, DiceLoss - 0.188, iou_score - 0.6975] \n",
      "\n",
      "Epoch: 25/100\n",
      "train: 100%|██████████| 267/267 [7:40:35<00:00, 103.51s/it, DiceLoss - 0.1394, iou_score - 0.767]   \n",
      "valid: 100%|██████████| 75/75 [09:48<00:00,  7.84s/it, DiceLoss - 0.1992, iou_score - 0.6801]\n",
      "\n",
      "Epoch: 26/100\n",
      "train: 100%|██████████| 267/267 [7:40:40<00:00, 103.52s/it, DiceLoss - 0.1373, iou_score - 0.7721]  \n",
      "valid: 100%|██████████| 75/75 [09:48<00:00,  7.84s/it, DiceLoss - 0.135, iou_score - 0.767]  \n",
      "Model saved!\n",
      "\n",
      "Epoch: 27/100\n",
      "train: 100%|██████████| 267/267 [7:40:39<00:00, 103.52s/it, DiceLoss - 0.1644, iou_score - 0.7377]  \n",
      "valid: 100%|██████████| 75/75 [09:53<00:00,  7.91s/it, DiceLoss - 0.1656, iou_score - 0.7239]\n",
      "\n",
      "Epoch: 28/100\n",
      "train: 100%|██████████| 267/267 [7:40:43<00:00, 103.53s/it, DiceLoss - 0.1472, iou_score - 0.7589]  \n",
      "valid: 100%|██████████| 75/75 [09:47<00:00,  7.84s/it, DiceLoss - 0.1526, iou_score - 0.7416]\n",
      "\n",
      "Epoch: 29/100\n",
      "train: 100%|██████████| 267/267 [7:40:48<00:00, 103.55s/it, DiceLoss - 0.1598, iou_score - 0.7487]  \n",
      "valid: 100%|██████████| 75/75 [09:48<00:00,  7.84s/it, DiceLoss - 0.1506, iou_score - 0.745] \n",
      "\n",
      "Epoch: 30/100\n",
      "train: 100%|██████████| 267/267 [7:40:42<00:00, 103.53s/it, DiceLoss - 0.1264, iou_score - 0.7895]  \n",
      "valid: 100%|██████████| 75/75 [09:49<00:00,  7.86s/it, DiceLoss - 0.1444, iou_score - 0.7547]\n",
      "\n",
      "Epoch: 31/100\n",
      "train: 100%|██████████| 267/267 [7:40:38<00:00, 103.51s/it, DiceLoss - 0.1604, iou_score - 0.7484]  \n",
      "valid: 100%|██████████| 75/75 [09:48<00:00,  7.84s/it, DiceLoss - 0.1629, iou_score - 0.7261]\n",
      "\n",
      "Epoch: 32/100\n",
      "train: 100%|██████████| 267/267 [7:40:40<00:00, 103.52s/it, DiceLoss - 0.1556, iou_score - 0.7501]  \n",
      "valid: 100%|██████████| 75/75 [09:48<00:00,  7.85s/it, DiceLoss - 0.1609, iou_score - 0.727] \n",
      "\n",
      "Epoch: 33/100\n",
      "train: 100%|██████████| 267/267 [7:40:38<00:00, 103.51s/it, DiceLoss - 0.1432, iou_score - 0.7602]  \n",
      "valid: 100%|██████████| 75/75 [09:48<00:00,  7.84s/it, DiceLoss - 0.1478, iou_score - 0.7499]\n",
      "\n",
      "Epoch: 34/100\n",
      "train: 100%|██████████| 267/267 [7:40:40<00:00, 103.52s/it, DiceLoss - 0.1289, iou_score - 0.7841]  \n",
      "valid: 100%|██████████| 75/75 [09:48<00:00,  7.85s/it, DiceLoss - 0.1293, iou_score - 0.7773]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 35/100\n",
      "train: 100%|██████████| 267/267 [7:40:35<00:00, 103.50s/it, DiceLoss - 0.1307, iou_score - 0.78]    \n",
      "valid: 100%|██████████| 75/75 [09:48<00:00,  7.84s/it, DiceLoss - 0.1862, iou_score - 0.6985]\n",
      "\n",
      "Epoch: 36/100\n",
      "train: 100%|██████████| 267/267 [7:40:43<00:00, 103.53s/it, DiceLoss - 0.1392, iou_score - 0.7718]  \n",
      "valid: 100%|██████████| 75/75 [09:48<00:00,  7.85s/it, DiceLoss - 0.1336, iou_score - 0.7693]\n",
      "\n",
      "Epoch: 37/100\n",
      "train:  37%|███▋      | 100/267 [2:52:56<5:17:30, 114.07s/it, DiceLoss - 0.1289, iou_score - 0.7795]"
     ]
    }
   ],
   "source": [
    "# Initialize the minimum dice loss and max IoU for saving the best model\n",
    "max_iou = 0\n",
    "\n",
    "# Number of epochs to train\n",
    "EPOCHS = 100\n",
    "\n",
    "# # Model save path\n",
    "# model_save_dir = 'test_models'\n",
    "# os.makedirs(model_save_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "# Run the training loop for the specified number of epochs\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\\nEpoch: {epoch + 1}/{EPOCHS}')\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    \n",
    "    # If validation IoU improves, save the model's state dictionary\n",
    "    if max_iou < valid_logs['iou_score']:\n",
    "        max_iou = valid_logs['iou_score']\n",
    "        torch.save(model.state_dict(), 'F:/CNN_LSTM/test_models/test_convlstm_b0.pth')\n",
    "        print('Model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max IoU: 0.623845636844635\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max IoU: {max_iou}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas Lessa\\AppData\\Local\\Temp\\ipykernel_2356\\2487791134.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('F:/CNN_LSTM/test_models/test_convlstm_b7.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNConvLSTMNet(\n",
       "  (cnn_backbone): EfficientNetB0Backbone(\n",
       "    (model): EfficientNet(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "                (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "                (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "                (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "                (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "                (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "                (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "                (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "                (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "          )\n",
       "          (1): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "          )\n",
       "          (2): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "          )\n",
       "          (3): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): MBConv(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): SiLU(inplace=True)\n",
       "                (scale_activation): Sigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "            (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "          )\n",
       "        )\n",
       "        (8): Conv2dNormActivation(\n",
       "          (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (classifier): Sequential(\n",
       "        (0): Dropout(p=0.2, inplace=True)\n",
       "        (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (8): Conv2dNormActivation(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (reduce_channels): Conv2d(1280, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (upsample): Upsample(scale_factor=(32.0, 32.0), mode='bilinear')\n",
       "  )\n",
       "  (conv_lstm): ConvLSTM(\n",
       "    (layers): ModuleList(\n",
       "      (0): ConvLSTMCell(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('F:/CNN_LSTM/test_models/test_convlstm_b0.pth'))\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input and output must have the same number of spatial dimensions, but got input with spatial dimensions of [512] and output size of torch.Size([512, 512]). Please provide input tensor in (N, C, d1, d2, ...,dK) format and output size in (o1, o2, ...,oK) format.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msegmentation_models_pytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_eval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display_binary_metrics\n\u001b[1;32m----> 3\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m \u001b[43mdisplay_binary_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mshow_iou\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_recall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_f1_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lucas Lessa\\Documents\\Spatial_and_Time_Model\\segmentation_models_pytorch\\utils\\model_eval.py:141\u001b[0m, in \u001b[0;36mdisplay_binary_metrics\u001b[1;34m(model, data_loader, device, threshold, show_accuracy, show_precision, show_recall, show_f1_score, show_iou)\u001b[0m\n\u001b[0;32m    139\u001b[0m inp, lab \u001b[38;5;241m=\u001b[39m inp\u001b[38;5;241m.\u001b[39mto(device), lab\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    140\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inp)\n\u001b[1;32m--> 141\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbilinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43malign_corners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# # Binary: Apply threshold\u001b[39;00m\n\u001b[0;32m    148\u001b[0m predictions \u001b[38;5;241m=\u001b[39m (outputs \u001b[38;5;241m>\u001b[39m threshold)\u001b[38;5;241m.\u001b[39mlong()\n",
      "File \u001b[1;32mc:\\programmers\\envs\\vit\\lib\\site-packages\\torch\\nn\\functional.py:3983\u001b[0m, in \u001b[0;36minterpolate\u001b[1;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[0;32m   3981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m   3982\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m-> 3983\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3984\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput and output must have the same number of spatial dimensions, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3985\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput with spatial dimensions of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and output size of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3986\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease provide input tensor in (N, C, d1, d2, ...,dK) format and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3987\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput size in (o1, o2, ...,oK) format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3988\u001b[0m         )\n\u001b[0;32m   3989\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[0;32m   3990\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_integer(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m size):\n",
      "\u001b[1;31mValueError\u001b[0m: Input and output must have the same number of spatial dimensions, but got input with spatial dimensions of [512] and output size of torch.Size([512, 512]). Please provide input tensor in (N, C, d1, d2, ...,dK) format and output size in (o1, o2, ...,oK) format."
     ]
    }
   ],
   "source": [
    "from segmentation_models_pytorch.utils.model_eval import display_binary_metrics\n",
    "\n",
    "metrics_df = display_binary_metrics(model, test_loader, DEVICE, threshold=0.5, \n",
    "                               show_iou=True, show_precision=True, show_recall=True, show_f1_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.utils.visualization import visualize_predictions\n",
    "\n",
    "# For binary segmentation:\n",
    "visualize_predictions(model, valid_loader, DEVICE, num_images=5, binary=True, threshold=0.5)\n",
    "\n",
    "# For multiclass segmentation:\n",
    "# visualize_predictions(model, valid_loader, DEVICE, num_images=5, binary=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
